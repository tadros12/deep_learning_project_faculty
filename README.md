# Arabic Handwritten Character Recognition (AHCD)

This project performs a comparative study of Deep Learning architectures for classifying Arabic handwritten characters using the **AHCD Dataset** (16,800 images).

## ğŸ“Š Project Overview
Arabic OCR is challenging due to the cursive nature of the script. We evaluated four architectures to determine the impact of **input resolution** and **transfer learning** on accuracy.

| Model | Type | Input Size | Accuracy | Observation |
|-------|------|------------|----------|-------------|
| **InceptionV3** | Transfer Learning | **75x75** (Upscaled) | **~80%** | ğŸ† **Best Performer** |
| ResNet50 | Transfer Learning | 32x32 | ~54% | Suffered from spatial information loss |
| MobileNetV2 | Transfer Learning | 32x32 | ~42% | Efficient but low accuracy on small inputs |
| VGG-19 | Custom (Scratch) | 32x32 | 3.5% | âŒ Failed (Vanishing Gradient) |

## ğŸ§  Methodology
1.  **Data Preprocessing:**
    * Images normalized to `[0, 1]`.
    * **Adapter Layer:** Learned `Conv2D` layer to convert Grayscale (1 channel) to RGB (3 channels) for pre-trained models.
    * **Upscaling:** InceptionV3 used a `Resizing` layer to convert 32x32 $\to$ 75x75.
2.  **Training:**
    * Optimizer: Adam
    * Loss: Categorical Crossentropy
    * Monitoring: TensorBoard

## ğŸ“‚ Project Structure
```text
â”œâ”€â”€ data/               # Dataset (GitIgnored)
â”œâ”€â”€ notebooks/          # Jupyter Notebooks for training
â”œâ”€â”€ models/             # Saved Keras models (GitIgnored)
â”œâ”€â”€ logs/               # TensorBoard logs
â”œâ”€â”€ doc/                # LaTeX Documentation & Report
â””â”€â”€ README.md           # Project Documentation
